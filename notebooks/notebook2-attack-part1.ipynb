{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tristan-allard/l1-ise-public/blob/main/notebooks/notebook2-attack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qOVUmdqyTjY"
   },
   "source": [
    "# L1 INFO - Introduction à la Sécurité (des données) - Projet 2023/2024\n",
    "\n",
    "__Intervenants :__ Tristan Allard, Mathieu Gestin, Mathieu Goessens \n",
    "\n",
    "Ce projet est issu d'un atelier réalisé en octobre 2021 dans le cadre du projet Rudi (https://blog.rudi.bzh/) par Tristan Allard et Javier Rojas~Balderrama.\n",
    "\n",
    "_Univ Rennes, CNRS, IRISA, INRIA_\n",
    "  \n",
    "This work is licensed under a [Creative Commons Zero v1.0 Universal License](https://creativecommons.org/publicdomain/zero/1.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "\n",
    "We warmly thank François Bodin and Luc Lesoil for their support on the data and the definition of the use-case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook __TWO__: The case for privacy -- Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OD991wF88Rio"
   },
   "source": [
    "## Step 0 (STARTER)\n",
    "\n",
    "Yes, raw data is not immune to re-identification! \n",
    "\n",
    "You are now going to perform a reidentification attack on a small set of targets. To this end, we will give you some auxiliary information (also called background knowledge) and programming tools for helping you query the dataset.\n",
    "1. You can display the buses validations dataset [here](#displayvalid). Feel free to to play with the filter menu, although the number of shown rows is limited. \n",
    "2. You can attack the dataset [Step 1](#attack) (do not be afraid to try!). \n",
    "3. In order to understand better your attacks and/or design other attacks, you can display informative measures about the _identifying power_ of the attributes of the dataset ([Step 2](#explain)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzLkzFP3fZm-"
   },
   "source": [
    "\n",
    " ### Download dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_Eju0G4yTjY",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!wget -nv -nc https://zenodo.org/record/5509268/files/buses.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4teYxHrfnuh"
   },
   "source": [
    "### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLHjpQH6yTjY"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import importlib\n",
    "import os\n",
    "from errno import ENOENT\n",
    "from pathlib import Path\n",
    "from typing import Optional, Sequence, Tuple, Union\n",
    "\n",
    "import folium\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import pyarrow.parquet as pq\n",
    "from folium.plugins import HeatMapWithTime\n",
    "from IPython import display, get_ipython\n",
    "from pandas import NA, DataFrame, Series, Timestamp\n",
    "from plotly.graph_objs import Figure, Scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup notebook constants and running environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fToRyDS0yTjY"
   },
   "outputs": [],
   "source": [
    "# project base directory\n",
    "BASE_DIRECTORY = Path(\".\")\n",
    "\n",
    "# detect running environment\n",
    "COLAB_ON = True if \"google.colab\" in str(get_ipython()) else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82e_w9dyyTjY"
   },
   "outputs": [],
   "source": [
    "# Set Ploty renderer\n",
    "if COLAB_ON:\n",
    "    pio.renderers.default = \"colab\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4gBkGhqpaL7"
   },
   "source": [
    "### Load and display raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUo9bi14yTk8"
   },
   "outputs": [],
   "source": [
    "# load dataset from file system\n",
    "def load_data(\n",
    "    path: Path,\n",
    ") -> DataFrame:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(ENOENT, os.strerror(ENOENT), path)\n",
    "\n",
    "    table = pq.read_table(path)\n",
    "    return table.to_pandas()\n",
    "\n",
    "\n",
    "# show a dataframe as a table\n",
    "def display_dataframe(\n",
    "    dataframe: DataFrame,\n",
    ") -> None:\n",
    "    if COLAB_ON:\n",
    "        spec = importlib.util.find_spec(\"google.colab\")\n",
    "        if spec:\n",
    "            data_table = importlib.import_module(\"google.colab.data_table\")\n",
    "            enable_dataframe_formatter = getattr(\n",
    "                data_table,\n",
    "                \"enable_dataframe_formatter\",\n",
    "            )\n",
    "\n",
    "            enable_dataframe_formatter()\n",
    "\n",
    "    display.display(dataframe[:20000] if COLAB_ON else dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show raw dataset\n",
    "\n",
    "<a id=\"displayvalid\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = BASE_DIRECTORY.joinpath(\"buses.parquet\")\n",
    "buses_dataset = load_data(path)\n",
    "display_dataframe(buses_dataset)\n",
    "\n",
    "####################\n",
    "# BEGIN : Observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-1jePEeyTk8"
   },
   "outputs": [],
   "source": [
    "# show dataset on a map\n",
    "def plot_heatmap(\n",
    "    dataframe: DataFrame,\n",
    "    group_column: str = \"departure_time\",\n",
    "    # Rennes GPS coordinates\n",
    "    location: Tuple[float, float] = (48.1147, -1.6794),\n",
    ") -> None:\n",
    "    _dataframe = dataframe.copy(deep=True)\n",
    "    timestamps = []\n",
    "    coordinates = []\n",
    "    for timestamp, coordinate in _dataframe.groupby(group_column):\n",
    "        timestamps.append(str(timestamp))\n",
    "        coordinates.append(\n",
    "            coordinate[\n",
    "                [\n",
    "                    \"stop_lat\",\n",
    "                    \"stop_lon\",\n",
    "                ]\n",
    "            ].values.tolist()\n",
    "        )\n",
    "\n",
    "    base_map = folium.Map(\n",
    "        location=location,\n",
    "        zoom_start=11,\n",
    "        tiles=\"https://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}{r}.png\",\n",
    "        # tiles=\"https://{s}.basemaps.cartocdn.com/dark_nolabels/{z}/{x}/{y}{r}.png\",\n",
    "        attr=\"CartoDB\",\n",
    "    )\n",
    "\n",
    "    heat_map = HeatMapWithTime(\n",
    "        data=coordinates,\n",
    "        index=timestamps,\n",
    "        auto_play=True,\n",
    "        min_speed=1,\n",
    "        radius=4,\n",
    "        max_opacity=0.5,\n",
    "    )\n",
    "\n",
    "    heat_map.add_to(base_map)\n",
    "    display.display(base_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KwNpJzamyTk8"
   },
   "outputs": [],
   "source": [
    "# Showing the heat map of validations only works on a local server\n",
    "if not COLAB_ON:\n",
    "    plot_heatmap(buses_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END : Observe\n",
    "####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65WnAyybppNH"
   },
   "source": [
    "## Step 1: Attack raw buses validations\n",
    "<a id=\"attack\"></a>\n",
    "\n",
    "Re-identification attacks are simple conceptually. They consist in selecting the subset of individuals whose records match the auxiliary information that the attacker has about them. If a single individual matches the adversarial knowledge, the success of the attack is clear (assuming that the adversarial knowledge is reliable). Otherwise the success is less clear. But when more than a single individual match the adversarial knowledge, is it really a failure? \n",
    "\n",
    "Lets have a look at an [example](#attackexample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop geospatial attributes from dataset\n",
    "def tidy_dataframe(\n",
    "    dataframe: DataFrame,\n",
    ") -> DataFrame:\n",
    "    dataframe_ = dataframe.copy()\n",
    "    return dataframe_[\n",
    "        [\n",
    "            \"departure_time\",\n",
    "            \"id\",\n",
    "            \"stop_name\",\n",
    "            \"route_short_name\",\n",
    "            \"stop_id\",\n",
    "            \"direction_id\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "\n",
    "# query the dataset by attribute and value\n",
    "def query(\n",
    "    dataframe: DataFrame,\n",
    "    name: str,\n",
    "    value: Union[str, int, float, Sequence[str]],\n",
    ") -> DataFrame:\n",
    "    return (\n",
    "        dataframe.query(f\"{name} == {value}\")\n",
    "        if isinstance(value, (int, float))\n",
    "        else dataframe.query(f'''{name} == \"{value}\"''')\n",
    "        if isinstance(value, str)\n",
    "        else dataframe.query(f\"{name} in {value}\")\n",
    "    )\n",
    "\n",
    "\n",
    "# filter dataset between two timestamps\n",
    "def between(\n",
    "    dataframe: DataFrame,\n",
    "    start: Union[str, Timestamp],\n",
    "    end: Union[str, Timestamp],\n",
    "    complement: bool = False,\n",
    ") -> DataFrame:\n",
    "    start_ = Timestamp(start) if not isinstance(start, Timestamp) else start\n",
    "    end_ = Timestamp(end) if not isinstance(end, Timestamp) else end\n",
    "    return (\n",
    "        (dataframe.set_index(\"departure_time\").loc[start_:end_].reset_index())\n",
    "        if not complement\n",
    "        else (\n",
    "            dataframe.loc[\n",
    "                (dataframe[\"departure_time\"] < start_)\n",
    "                | (dataframe[\"departure_time\"] > end_)\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# intersect two datasets with a common attribute ('on')\n",
    "def intersect(\n",
    "    right: DataFrame,\n",
    "    left: DataFrame,\n",
    "    on: Optional[Sequence[str]] = None,\n",
    "    how: str = \"inner\",\n",
    ") -> Optional[DataFrame]:\n",
    "    on_ = on if on else right.columns.values.tolist()\n",
    "    return pd.merge(\n",
    "        right,\n",
    "        left,\n",
    "        how=how,\n",
    "        on=on_,\n",
    "    )  # if set(rvalues) == set(lvalues) else None\n",
    "\n",
    "\n",
    "# get distinct rows from a dataset grouping by a 'subset'\n",
    "def distinct(\n",
    "    dataframe: DataFrame,\n",
    "    subset: Union[str, Sequence[str]],\n",
    ") -> DataFrame:\n",
    "    return dataframe.drop_duplicates(subset=subset)\n",
    "\n",
    "\n",
    "# count rows by name and value\n",
    "def count_by(\n",
    "    dataframe: DataFrame,\n",
    "    name: str,\n",
    "    value: Union[str, int, float],\n",
    "    *,\n",
    "    frequency: str = \"15T\",\n",
    ") -> DataFrame:\n",
    "    dataframe_ = (\n",
    "        dataframe[dataframe[name] == value]\n",
    "        .set_index(\"departure_time\")\n",
    "        .groupby(\n",
    "            [\n",
    "                pd.Grouper(level=\"departure_time\", freq=frequency),\n",
    "            ]\n",
    "        )\n",
    "        .count()\n",
    "    )\n",
    "\n",
    "    # #domain = pd.date_range(start=dataframe_.index.min(), end=dataframe_.index.max(), freq=\"15T\")\n",
    "    # #dataframe_ = dataframe_.reindex(domain, method=None, fill_value=NA)\n",
    "    # #dataframe_.replace(0, np.NAN, inplace=True)\n",
    "    # #display_dataframe(dataframe_)\n",
    "    return dataframe_[dataframe_.columns[0]].to_frame(name=\"count\")\n",
    "\n",
    "\n",
    "# show a timeseries graph of a selected attribute\n",
    "def plot_dataset(\n",
    "    dataframe: DataFrame,\n",
    "    column: str,\n",
    ") -> None:\n",
    "    figure = Figure()\n",
    "    scatter = Scatter(\n",
    "        x=dataframe.index,\n",
    "        y=dataframe[column],\n",
    "        mode=\"lines\",\n",
    "        name=\"values\",\n",
    "        connectgaps=False,\n",
    "    )\n",
    "\n",
    "    figure.add_trace(scatter)\n",
    "    figure.update_layout(\n",
    "        showlegend=False,\n",
    "        title_text=column,\n",
    "        template=\"simple_white\",\n",
    "    )\n",
    "\n",
    "    figure.update_xaxes(showgrid=True)\n",
    "    figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of a re-identification attack\n",
    "<a id='attackexample'></a>\n",
    "\n",
    "Somebody said:\n",
    "\n",
    "> \"*I often take the bus in the morning to go to Beaulieu from the 'Anne de Bretagne' bus stop in Cesson* \"\n",
    "\n",
    "Is this information enough to discover the mobility patterns of that person?\n",
    "\n",
    "A short summary of implemented methods used to perform the attack, refer to the example below for the use (or if you feel confortable use the **Pandas** API directly):\n",
    "\n",
    "- `query`:  perform a query on the dataset by attribute name and value.\n",
    "- `between`:  filter dataset between two timestamps.\n",
    "- `intersect`: \"intersect\" two datasets with a common attribute (the 'on' attribute). Please note that we call it \"intersection\" but it is actually a \"join\" operation (in database language).\n",
    "- `distinct`: get distinct rows from a dataset grouping by a 'subset'.\n",
    "\n",
    "Have a look at the code below that implements this attack. You can also [go straight to your targets](#attacktargets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# BEGIN : Observe\n",
    "\n",
    "# remove geo-spatial information from the dataset\n",
    "dataset = tidy_dataframe(buses_dataset)\n",
    "\n",
    "# show the dataset\n",
    "print(\"Initial dataset\")\n",
    "display_dataframe(dataset)\n",
    "\n",
    "# query: \"I take the bus from the bus stop 'Anne de Bretagne'\"\n",
    "q_1 = query(dataset, \"stop_name\", \"Anne de Bretagne\")\n",
    "\n",
    "# query: \"I take the bus going to Beaulieu (city center)\"\n",
    "q_2 = query(dataset, \"direction_id\", 0)\n",
    "\n",
    "# intersect results of 'q_1' and 'q_2'\n",
    "q_3 = intersect(q_1, q_2, on=[\"id\"])\n",
    "\n",
    "# show results of intesection done on 'q_3'\n",
    "print(\"Result of the intersection of queries 1 & 2\")\n",
    "display_dataframe(q_3)\n",
    "\n",
    "# check how many different users are in query 'q_3'\n",
    "q_4 = distinct(q_3, [\"id\"])\n",
    "\n",
    "# show results of query 'q_3'\n",
    "# => since there is only one row we found the user!\")\n",
    "print(\"Result of checking different `id` in previous result\")\n",
    "display_dataframe(q_4)\n",
    "\n",
    "# query: all travels of the user ('id') of query 'q_4'\n",
    "q_5 = query(dataset, \"id\", 175)\n",
    "\n",
    "# show results of query 'q_5'\n",
    "print(\"Complete dataset of the user with `id` 175\")\n",
    "display_dataframe(q_5)\n",
    "\n",
    "# get the travels count of the user ('id') of query 'q_3' in a timeline\n",
    "q_6 = count_by(dataset, \"id\", 175)\n",
    "\n",
    "# plot results of query 'q_6'\n",
    "plot_dataset(q_6, \"count\")\n",
    "\n",
    "# for the curious:\n",
    "# all-in-one 'plain vanilla' code equivalent as follows\n",
    "# (results are not printed on screen)\n",
    "target = dataset.query(\n",
    "    \"stop_name == 'Anne de Bretagne' & direction_id == 0\"\n",
    ").drop_duplicates(\n",
    "    subset=[\n",
    "        \"id\",\n",
    "        \"stop_name\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# END : Observe\n",
    "####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food for thoughts\n",
    "<a id='attacktargets'></a>\n",
    "\n",
    "Here below there is auxiliary information that you have on different targets. Can you re-identify them based on the available dataset and all their bus validations? \n",
    "\n",
    "```\n",
    "####################\n",
    "# BEGIN : Answer\n",
    "```\n",
    "\n",
    "> - Target 1: *I remember that on __Sept the 6th 2021__ I had to take the bus very early __before 6:30AM__. I leave close to the __'Cesson Collège'__ bus stop, yes.*\n",
    "> - Target 2: *I usually take the bus from __'Saint-Sulpice'__, the __'Zone d'Activités'__. But during the __Autumn 2021 holidays__ I stayed at my parents' home, close to __the lakes__ there in __Cesson__. I took the bus __'217'__ a couple of times at that time. I think it is not the __'217'__ line anymore today but the __'216'__ line. I love taking the bus* <3 .\n",
    "> - Target 3: *I live __Blvd Villebois Mareuil__ below the river. I __do not like the big avenue__ going from West to East with crowded buses so I usually walk a bit in order to take the bus at a __quieter place__. By the way, I often take the bus from the __RU in Beaulieu__.*.\n",
    "\n",
    "```\n",
    "# END : Answer\n",
    "####################\n",
    "```\n",
    "\n",
    "__Warning:__ There might be discrepancies with the current public transportation map. You can use the [global map](https://www.star.fr/se-deplacer/plans-du-reseau) for spotting the right bus stops for Target 2 and Target 3 though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# BEGIN : Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target 1\n",
    "dataset = tidy_dataframe(buses_dataset)\n",
    "\n",
    "# TODO YOUR code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target 2\n",
    "dataset = tidy_dataframe(buses_dataset)\n",
    "\n",
    "# TODO YOUR code here!\n",
    "\n",
    "# NOTE: To use 'between' set the start and end dates as strings:\n",
    "#       result = between(dataset, \"2021-08-01\", \"2021-08-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target 3\n",
    "dataset = tidy_dataframe(buses_dataset)\n",
    "\n",
    "# TODO YOUR code here!\n",
    "\n",
    "# NOTE: To test several values of an attribute at once, provide a list to query:\n",
    "#       values = [\"Tournebride\", \"Le Mail\", \"Maison d'Accueil\"]\n",
    "#       result = query(dataset, \"stop_name\", values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END : Code\n",
    "####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why was this auxiliary information sufficient for enabling your attacks? Displaying the anonymity sets as done in [Step 2](#explain) can give some explainations..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "NmKSCNfpfOQ-",
    "qzLkzFP3fZm-",
    "O4teYxHrfnuh",
    "-kXTLBmBfxuL",
    "ZV4MJqgogTB0",
    "F-CFufprhULZ",
    "b5Hiwx5O7gXw",
    "tawuGE-n9PTw",
    "s4gBkGhqpaL7"
   ],
   "include_colab_link": true,
   "name": "a2r2-notebook02.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "d5511370cecfc9f72087461b207d0bd90f18099e89758b2a61eb3e3243f66294"
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
